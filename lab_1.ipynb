{"cells":[{"cell_type":"markdown","metadata":{"id":"RBUwvhvTOpmQ"},"source":["# Lab 1: numerical derivatives\n","\n","---\n","\n","* *This collection of exercises is meant for you to practice this week's contents. It contains problems for which computer code, hand work, or both are required. This is noted for each individual problem with ```Python```, ```Hand```, or ```Both```, respectively.*\n","* *Labs are not marked. Their aim is to get prepared for the assessments.*\n","* *Exercises marked with an asterisk are recommended to be attempted during the lab session.*\n","\n","*Solutions will be made available on the Tuesday following the lab.*\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"dfgDF5D7OpmR"},"source":["### 1. Welcome back (to Python!)*\n","\n","In this exercise, we will test the $O(h^2)$ approximation for the first differential. Consider the function $f(x)=e^{-x}\\sin(x)$ defined in $[0,9]$.\n","\n","<br />\n","\n","***1.1.*** Compute $f^{(1)}(x)$ numerically using a for loop. Calculate the error and plot it as a function of $x$. Consider $h=1$, $0.1$, and $0.01$. ``[Python]``\n","\n","***1.2.*** Calculate $f^{(1)}(x)$ numerically using indexing. Compare the times required to do the computations with the for loop technique. Repeat for different step sizes. **Hint**: Use the ```time```  command included in the ```time``` library. ``[Python]``\n"]},{"cell_type":"markdown","metadata":{"id":"KahcXWuxOpmS"},"source":["### 2. Non-central differences.*  \n","\n","We can use the definition of first order derivative to obtain another numerical approximation:\n","\n","<br />\n","\n","\\begin{equation}\n","\\frac{f(x+h)-f(x)}{h} \\xrightarrow[h\\rightarrow0] {}f^{(1)}(x).\n","\\end{equation}\n","\n","If we choose $h$ small enough, we can say that the left hand side of this new formula is a good approximation to the first derivative. We call this formula the _non-central_ (first order) method.\n","\n","<br />\n","\n","***2.1.*** Using a similar method as that of Ex. 1, show that the truncation error is given by\n","\n","<br />\n","\n","$$\n","E_{trunc}=-f^{(2)}(\\xi) \\frac{h}{2}, \\ \\ \\ \\ \\ \\xi\\in [x,x+h].\n","$$\n","\n","<br />\n","\n","How is it compared to the central difference? Which are the advantages and disadvantages? ``[Hand]``\n","\n","***2.2.*** Implement this algorithm in Python and use it to compute the approximation of the function defined in Ex. 1. with $h=0.5$. Compare it with the already implemented $O(h^2)$ formula. ``[Python]``\n","\n","\n","***2.3.*** Compute and plot the errors for both $O(h)$ and $O(h^2)$ approximations at an arbitrary point $x_0$ as a function of $h$ (as done in the Lecture). ``[Python]``\n"]},{"cell_type":"markdown","metadata":{"id":"WjOi8rb6OpmT"},"source":["### 3. Higher order expressions.\n","\n","As you may have noticed, we can find many arbitrary approximations by properly manipulating Taylor series and the corresponding truncation errors. In this case, we will derive yet another central difference formula with some good properties.\n","\n","<br />\n","\n","***3.1*** Using Taylor series, find the truncation error $E_{trunc}$ for the following approximation ``[Hand]``\n","\n","<br />\n","\n","$$\n","f^{(1)}(x)=\\frac{-f(x+2h)+8f(x+h)-8f(x-h)+f(x-2h)}{12h} + E_{trunc}.\n","$$\n","\n","<br />\n","\n","***3.2.*** Write a function in Python implementing the new approximation. Compare its error with the other methods as done in 2.3. ``[Python]``\n","\n","\n","***3.3.*** (optional) Following the lecture notes, find an optimal step size minimising the overall error (i.e., the sum of both truncation and rounding errors). What is the optimal step size for computing the derivative of $f(x)=\\cos(x)$ if we work with 4 decimal digits? How does this value compare with that needed by the $O(h^2)$ formula? ``[Hand]``"]},{"cell_type":"markdown","metadata":{"id":"QESqzXqjOpmT"},"source":["### 4. Higher order derivatives.\n","\n","A colleague has shared the following code with us:\n","\n","```\n","def num_dif2_Oh2(f):\n","    return (f[2::] + f[0:-2] - 2 * f[1:-1]) / h**2\n","```\n","\n","She mentioned that this Python function computes an $O(h^2)$ approximation of the second differential.\n","\n","<br />\n","\n","***4.1.*** Verify that this is true for the function defined in Ex.1. **Hint**: Compare the numerical and analytical solutions. ``[Python]``\n","\n","***4.2.*** Write the approximation formula implemented in the code. ``[Hand]``\n","\n","\n","***4.3.***  Show that the truncation error is given by\n","\n","<br />\n","\n","$$\n","E_{trunc}=-\\frac{h^2}{12}f^{(4)}(\\xi), \\ \\ \\ \\ \\ \\xi\\in[x-h,x+h].\n","$$\n","\n","<br />\n","\n","&nbsp; &nbsp; **Hint**: Yes, use the Taylor series again! ``[Hand]``"]},{"cell_type":"markdown","metadata":{"id":"oNiRTIqjOpmU"},"source":["### 5. In your spare time.\n","\n","We have seen that there exist ***many*** expressions for approximating numerical differentials depending on the order of the expression (i.e., $O(h^n)$), if it is centred or not, or even in the order of the differential (i.e., $f^{(n)}$). This leads us to ask \"how many expressions are available?\" The answer is as vague as the question: there are as many as we want! Then, a more sensible question is \"is there any procedure to find an approximation provided the order of the expression, the points it involves, and/or the order of the differential?\" The answer is yes, there exists, and was presented by Fornberg in his paper \"Generation of Finite Difference Formulas on Arbitrarily Spaced Grids\" (Mathematics of Computation, 51 (184): 699â€“706, 1988). This method allows to find the coefficients for any arbitrary set of requirements. A very nice implementation is available in the [following blog](http://web.media.mit.edu/~crtaylor/calculator.html). Visit the website and verify that the expressions we have seen are just special cases of an infinite set of possibilities!"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}